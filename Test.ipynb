{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboardX'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-ad6a12f5d88c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastMRI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mTtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlowfieldsim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msimulator_MRI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mUnet_MRI_7T3\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mUnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\MRI_7T3\\Unet_MRI_7T3.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlowfieldsim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlowfieldsim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msimulator_MRI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboardX\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboardX'"
     ]
    }
   ],
   "source": [
    "import lowfieldsim\n",
    "import scipy.io\n",
    "from fastMRI.data import transforms as Ttorch\n",
    "import lowfieldsim as simulator_MRI\n",
    "import Unet_MRI_7T3 as Unet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents = scipy.io.loadmat('fat-water@3T-3echo.mat')\n",
    "B0_low = 0.3\n",
    "sorted(mat_contents.keys())\n",
    "k_high_T = Ttorch.to_tensor(mat_contents['k_high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([168, 168, 1, 3, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(k_high_T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=15> Testing simulator with known input \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_lowfieldsim = simulator_MRI.lowfieldsim()\n",
    "low_res_real, high_res_real,img_low_combined ,img_high_combined = Test_lowfieldsim.lowfieldsim(k_high_T[:128,:128])\n",
    "# *_res_real is image with size [image_w, image_h, #coils]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_low_combined = img_low_combined.numpy()\n",
    "# img_low_combined = (img_low_combined - np.amin(img_low_combined))/ (np.amax(img_low_combined)-np.amin(img_low_combined))\n",
    "# print(low_res_real[0,0,0])\n",
    "# print(np.amin(img_low_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c2fd86501219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Accquired\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m121\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_high_combined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Accquired\n",
    "plt.subplot(121),\n",
    "plt.imshow(np.sqrt((img_high_combined)), cmap='gray')\n",
    "plt.title('Accquired @ 3T')\n",
    "\n",
    "# low field\n",
    "plt.subplot(122),\n",
    "plt.imshow(np.sqrt((img_low_combined)), cmap='gray');\n",
    "plt.title(\"Simulated @ 0.5 T\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=15> Testing MRI_Unet get_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_get_data = Unet.get_data\n",
    "input_mr, target, output_gt = Testing_get_data(k_high_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target should be lowfield MRI\n",
    "print(target.shape)\n",
    "target_per = target.permute(1,2,0)\n",
    "print(target.shape)\n",
    "\n",
    "#Output ground thrut is the high field image\n",
    "print(output_gt.shape)\n",
    "output_gt_per = output_gt.permute(1,2,0)\n",
    "print(output_gt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Accquired\n",
    "plt.subplot(121),\n",
    "plt.imshow(np.sqrt(torch.sum(output_gt_per,2)), cmap='gray')\n",
    "plt.title('Accquired @ 3T')\n",
    "\n",
    "# low field\n",
    "plt.subplot(122),\n",
    "plt.imshow(np.sqrt(torch.sum(target_per,2)), cmap='gray');\n",
    "plt.title(\"Simulated @ 0.5 T\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font size=15> Testing MRI_Unet end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnetModel(\n",
      "  (down_sample_layers): ModuleList(\n",
      "    (0): ConvBlock(in_chans=8, out_chans=8, drop_prob=0.0)\n",
      "    (1): ConvBlock(in_chans=8, out_chans=16, drop_prob=0.0)\n",
      "    (2): ConvBlock(in_chans=16, out_chans=32, drop_prob=0.0)\n",
      "    (3): ConvBlock(in_chans=32, out_chans=64, drop_prob=0.0)\n",
      "  )\n",
      "  (conv): ConvBlock(in_chans=64, out_chans=64, drop_prob=0.0)\n",
      "  (up_sample_layers): ModuleList(\n",
      "    (0): ConvBlock(in_chans=128, out_chans=32, drop_prob=0.0)\n",
      "    (1): ConvBlock(in_chans=64, out_chans=16, drop_prob=0.0)\n",
      "    (2): ConvBlock(in_chans=32, out_chans=8, drop_prob=0.0)\n",
      "    (3): ConvBlock(in_chans=16, out_chans=8, drop_prob=0.0)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(4, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    momentum: 0\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "Epoch = [   0/2000] TrainLoss = 0.4286 , Actual loss on HF:0.2231\n",
      "Epoch = [  10/2000] TrainLoss = 0.4267 , Actual loss on HF:0.2253\n",
      "Epoch = [  20/2000] TrainLoss = 0.4309 , Actual loss on HF:0.2245\n",
      "Epoch = [  30/2000] TrainLoss = 0.431 , Actual loss on HF:0.2212\n",
      "Epoch = [  40/2000] TrainLoss = 0.4266 , Actual loss on HF:0.2243\n",
      "Epoch = [  50/2000] TrainLoss = 0.4286 , Actual loss on HF:0.2211\n",
      "Epoch = [  60/2000] TrainLoss = 0.4284 , Actual loss on HF:0.2184\n",
      "Epoch = [  70/2000] TrainLoss = 0.4328 , Actual loss on HF:0.2213\n",
      "Epoch = [  80/2000] TrainLoss = 0.4275 , Actual loss on HF:0.2174\n",
      "Epoch = [  90/2000] TrainLoss = 0.4292 , Actual loss on HF:0.2163\n",
      "Epoch = [ 100/2000] TrainLoss = 0.4306 , Actual loss on HF:0.2151\n",
      "Epoch = [ 110/2000] TrainLoss = 0.4273 , Actual loss on HF:0.2135\n",
      "Epoch = [ 120/2000] TrainLoss = 0.4285 , Actual loss on HF:0.2084\n",
      "Epoch = [ 130/2000] TrainLoss = 0.4304 , Actual loss on HF:0.2087\n",
      "Epoch = [ 140/2000] TrainLoss = 0.4267 , Actual loss on HF:0.2077\n",
      "Epoch = [ 150/2000] TrainLoss = 0.4301 , Actual loss on HF:0.2121\n",
      "Epoch = [ 160/2000] TrainLoss = 0.4304 , Actual loss on HF:0.2115\n",
      "Epoch = [ 170/2000] TrainLoss = 0.4312 , Actual loss on HF:0.2176\n",
      "Epoch = [ 180/2000] TrainLoss = 0.4271 , Actual loss on HF:0.2186\n",
      "Epoch = [ 190/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2149\n",
      "Epoch = [ 200/2000] TrainLoss = 0.4262 , Actual loss on HF:0.2188\n",
      "Epoch = [ 210/2000] TrainLoss = 0.4355 , Actual loss on HF:0.2162\n",
      "Epoch = [ 220/2000] TrainLoss = 0.4294 , Actual loss on HF:0.2153\n",
      "Epoch = [ 230/2000] TrainLoss = 0.4311 , Actual loss on HF:0.2181\n",
      "Epoch = [ 240/2000] TrainLoss = 0.4281 , Actual loss on HF:0.2196\n",
      "Epoch = [ 250/2000] TrainLoss = 0.425 , Actual loss on HF:0.216\n",
      "Epoch = [ 260/2000] TrainLoss = 0.4265 , Actual loss on HF:0.2197\n",
      "Epoch = [ 270/2000] TrainLoss = 0.4214 , Actual loss on HF:0.2229\n",
      "Epoch = [ 280/2000] TrainLoss = 0.4305 , Actual loss on HF:0.23\n",
      "Epoch = [ 290/2000] TrainLoss = 0.4249 , Actual loss on HF:0.2213\n",
      "Epoch = [ 300/2000] TrainLoss = 0.4262 , Actual loss on HF:0.2162\n",
      "Epoch = [ 310/2000] TrainLoss = 0.4321 , Actual loss on HF:0.2105\n",
      "Epoch = [ 320/2000] TrainLoss = 0.4296 , Actual loss on HF:0.2062\n",
      "Epoch = [ 330/2000] TrainLoss = 0.4301 , Actual loss on HF:0.2078\n",
      "Epoch = [ 340/2000] TrainLoss = 0.429 , Actual loss on HF:0.2097\n",
      "Epoch = [ 350/2000] TrainLoss = 0.4278 , Actual loss on HF:0.2113\n",
      "Epoch = [ 360/2000] TrainLoss = 0.4306 , Actual loss on HF:0.2092\n",
      "Epoch = [ 370/2000] TrainLoss = 0.4276 , Actual loss on HF:0.2076\n",
      "Epoch = [ 380/2000] TrainLoss = 0.4331 , Actual loss on HF:0.2082\n",
      "Epoch = [ 390/2000] TrainLoss = 0.43 , Actual loss on HF:0.2082\n",
      "Epoch = [ 400/2000] TrainLoss = 0.4267 , Actual loss on HF:0.2056\n",
      "Epoch = [ 410/2000] TrainLoss = 0.4298 , Actual loss on HF:0.2052\n",
      "Epoch = [ 420/2000] TrainLoss = 0.4295 , Actual loss on HF:0.2048\n",
      "Epoch = [ 430/2000] TrainLoss = 0.4326 , Actual loss on HF:0.2079\n",
      "Epoch = [ 440/2000] TrainLoss = 0.4249 , Actual loss on HF:0.2093\n",
      "Epoch = [ 450/2000] TrainLoss = 0.4291 , Actual loss on HF:0.2098\n",
      "Epoch = [ 460/2000] TrainLoss = 0.4301 , Actual loss on HF:0.2104\n",
      "Epoch = [ 470/2000] TrainLoss = 0.4266 , Actual loss on HF:0.2141\n",
      "Epoch = [ 480/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2132\n",
      "Epoch = [ 490/2000] TrainLoss = 0.4303 , Actual loss on HF:0.2104\n",
      "Epoch = [ 500/2000] TrainLoss = 0.4283 , Actual loss on HF:0.2101\n",
      "Epoch = [ 510/2000] TrainLoss = 0.4253 , Actual loss on HF:0.211\n",
      "Epoch = [ 520/2000] TrainLoss = 0.4266 , Actual loss on HF:0.2096\n",
      "Epoch = [ 530/2000] TrainLoss = 0.4297 , Actual loss on HF:0.2089\n",
      "Epoch = [ 540/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2109\n",
      "Epoch = [ 550/2000] TrainLoss = 0.4277 , Actual loss on HF:0.2117\n",
      "Epoch = [ 560/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2086\n",
      "Epoch = [ 570/2000] TrainLoss = 0.4261 , Actual loss on HF:0.2087\n",
      "Epoch = [ 580/2000] TrainLoss = 0.4298 , Actual loss on HF:0.2096\n",
      "Epoch = [ 590/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2117\n",
      "Epoch = [ 600/2000] TrainLoss = 0.43 , Actual loss on HF:0.2091\n",
      "Epoch = [ 610/2000] TrainLoss = 0.4262 , Actual loss on HF:0.2096\n",
      "Epoch = [ 620/2000] TrainLoss = 0.4268 , Actual loss on HF:0.2097\n",
      "Epoch = [ 630/2000] TrainLoss = 0.4282 , Actual loss on HF:0.211\n",
      "Epoch = [ 640/2000] TrainLoss = 0.4305 , Actual loss on HF:0.2132\n",
      "Epoch = [ 650/2000] TrainLoss = 0.4294 , Actual loss on HF:0.2087\n",
      "Epoch = [ 660/2000] TrainLoss = 0.4286 , Actual loss on HF:0.2092\n",
      "Epoch = [ 670/2000] TrainLoss = 0.427 , Actual loss on HF:0.2114\n",
      "Epoch = [ 680/2000] TrainLoss = 0.4275 , Actual loss on HF:0.2126\n",
      "Epoch = [ 690/2000] TrainLoss = 0.4285 , Actual loss on HF:0.2107\n",
      "Epoch = [ 700/2000] TrainLoss = 0.4268 , Actual loss on HF:0.2105\n",
      "Epoch = [ 710/2000] TrainLoss = 0.4247 , Actual loss on HF:0.2125\n",
      "Epoch = [ 720/2000] TrainLoss = 0.426 , Actual loss on HF:0.2133\n",
      "Epoch = [ 730/2000] TrainLoss = 0.4278 , Actual loss on HF:0.2117\n",
      "Epoch = [ 740/2000] TrainLoss = 0.4272 , Actual loss on HF:0.2109\n",
      "Epoch = [ 750/2000] TrainLoss = 0.428 , Actual loss on HF:0.2136\n",
      "Epoch = [ 760/2000] TrainLoss = 0.4307 , Actual loss on HF:0.2167\n",
      "Epoch = [ 770/2000] TrainLoss = 0.4292 , Actual loss on HF:0.2182\n",
      "Epoch = [ 780/2000] TrainLoss = 0.4303 , Actual loss on HF:0.2145\n",
      "Epoch = [ 790/2000] TrainLoss = 0.4289 , Actual loss on HF:0.2197\n",
      "Epoch = [ 800/2000] TrainLoss = 0.4278 , Actual loss on HF:0.2203\n",
      "Epoch = [ 810/2000] TrainLoss = 0.4247 , Actual loss on HF:0.2211\n",
      "Epoch = [ 820/2000] TrainLoss = 0.4284 , Actual loss on HF:0.217\n",
      "Epoch = [ 830/2000] TrainLoss = 0.4297 , Actual loss on HF:0.2221\n",
      "Epoch = [ 840/2000] TrainLoss = 0.4323 , Actual loss on HF:0.2229\n",
      "Epoch = [ 850/2000] TrainLoss = 0.4267 , Actual loss on HF:0.2201\n",
      "Epoch = [ 860/2000] TrainLoss = 0.4334 , Actual loss on HF:0.2248\n",
      "Epoch = [ 870/2000] TrainLoss = 0.4297 , Actual loss on HF:0.2278\n",
      "Epoch = [ 880/2000] TrainLoss = 0.4268 , Actual loss on HF:0.2246\n",
      "Epoch = [ 890/2000] TrainLoss = 0.4306 , Actual loss on HF:0.2255\n",
      "Epoch = [ 900/2000] TrainLoss = 0.4217 , Actual loss on HF:0.229\n",
      "Epoch = [ 910/2000] TrainLoss = 0.4252 , Actual loss on HF:0.2296\n",
      "Epoch = [ 920/2000] TrainLoss = 0.4274 , Actual loss on HF:0.2285\n",
      "Epoch = [ 930/2000] TrainLoss = 0.4302 , Actual loss on HF:0.2283\n",
      "Epoch = [ 940/2000] TrainLoss = 0.4238 , Actual loss on HF:0.2308\n",
      "Epoch = [ 950/2000] TrainLoss = 0.4302 , Actual loss on HF:0.2303\n",
      "Epoch = [ 960/2000] TrainLoss = 0.426 , Actual loss on HF:0.2312\n",
      "Epoch = [ 970/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2304\n",
      "Epoch = [ 980/2000] TrainLoss = 0.4263 , Actual loss on HF:0.2353\n",
      "Epoch = [ 990/2000] TrainLoss = 0.427 , Actual loss on HF:0.2317\n",
      "Epoch = [1000/2000] TrainLoss = 0.4279 , Actual loss on HF:0.2331\n",
      "Epoch = [1010/2000] TrainLoss = 0.4244 , Actual loss on HF:0.2341\n",
      "Epoch = [1020/2000] TrainLoss = 0.4277 , Actual loss on HF:0.2357\n",
      "Epoch = [1030/2000] TrainLoss = 0.4296 , Actual loss on HF:0.2312\n",
      "Epoch = [1040/2000] TrainLoss = 0.4281 , Actual loss on HF:0.2303\n",
      "Epoch = [1050/2000] TrainLoss = 0.4272 , Actual loss on HF:0.2299\n",
      "Epoch = [1060/2000] TrainLoss = 0.4261 , Actual loss on HF:0.2318\n",
      "Epoch = [1070/2000] TrainLoss = 0.4229 , Actual loss on HF:0.2291\n",
      "Epoch = [1080/2000] TrainLoss = 0.43 , Actual loss on HF:0.231\n",
      "Epoch = [1090/2000] TrainLoss = 0.4299 , Actual loss on HF:0.2295\n",
      "Epoch = [1100/2000] TrainLoss = 0.4303 , Actual loss on HF:0.2335\n",
      "Epoch = [1110/2000] TrainLoss = 0.4276 , Actual loss on HF:0.2368\n",
      "Epoch = [1120/2000] TrainLoss = 0.4307 , Actual loss on HF:0.2341\n",
      "Epoch = [1130/2000] TrainLoss = 0.4301 , Actual loss on HF:0.2333\n",
      "Epoch = [1140/2000] TrainLoss = 0.4289 , Actual loss on HF:0.2343\n",
      "Epoch = [1150/2000] TrainLoss = 0.4248 , Actual loss on HF:0.2333\n",
      "Epoch = [1160/2000] TrainLoss = 0.4281 , Actual loss on HF:0.2301\n",
      "Epoch = [1170/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2294\n",
      "Epoch = [1180/2000] TrainLoss = 0.4274 , Actual loss on HF:0.2258\n",
      "Epoch = [1190/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2245\n",
      "Epoch = [1200/2000] TrainLoss = 0.4257 , Actual loss on HF:0.2244\n",
      "Epoch = [1210/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2265\n",
      "Epoch = [1220/2000] TrainLoss = 0.4292 , Actual loss on HF:0.2253\n",
      "Epoch = [1230/2000] TrainLoss = 0.4269 , Actual loss on HF:0.2238\n",
      "Epoch = [1240/2000] TrainLoss = 0.427 , Actual loss on HF:0.2258\n",
      "Epoch = [1250/2000] TrainLoss = 0.423 , Actual loss on HF:0.2242\n",
      "Epoch = [1260/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2268\n",
      "Epoch = [1270/2000] TrainLoss = 0.4274 , Actual loss on HF:0.2278\n",
      "Epoch = [1280/2000] TrainLoss = 0.4264 , Actual loss on HF:0.2257\n",
      "Epoch = [1290/2000] TrainLoss = 0.4296 , Actual loss on HF:0.2293\n",
      "Epoch = [1300/2000] TrainLoss = 0.429 , Actual loss on HF:0.2308\n",
      "Epoch = [1310/2000] TrainLoss = 0.4272 , Actual loss on HF:0.2334\n",
      "Epoch = [1320/2000] TrainLoss = 0.4265 , Actual loss on HF:0.232\n",
      "Epoch = [1330/2000] TrainLoss = 0.4283 , Actual loss on HF:0.2342\n",
      "Epoch = [1340/2000] TrainLoss = 0.4295 , Actual loss on HF:0.2306\n",
      "Epoch = [1350/2000] TrainLoss = 0.4261 , Actual loss on HF:0.2306\n",
      "Epoch = [1360/2000] TrainLoss = 0.4289 , Actual loss on HF:0.235\n",
      "Epoch = [1370/2000] TrainLoss = 0.4315 , Actual loss on HF:0.2343\n",
      "Epoch = [1380/2000] TrainLoss = 0.427 , Actual loss on HF:0.2399\n",
      "Epoch = [1390/2000] TrainLoss = 0.4294 , Actual loss on HF:0.2407\n",
      "Epoch = [1400/2000] TrainLoss = 0.4323 , Actual loss on HF:0.2404\n",
      "Epoch = [1410/2000] TrainLoss = 0.4318 , Actual loss on HF:0.2382\n",
      "Epoch = [1420/2000] TrainLoss = 0.4322 , Actual loss on HF:0.2369\n",
      "Epoch = [1430/2000] TrainLoss = 0.4305 , Actual loss on HF:0.2314\n",
      "Epoch = [1440/2000] TrainLoss = 0.4268 , Actual loss on HF:0.2313\n",
      "Epoch = [1450/2000] TrainLoss = 0.4254 , Actual loss on HF:0.2318\n",
      "Epoch = [1460/2000] TrainLoss = 0.4301 , Actual loss on HF:0.2307\n",
      "Epoch = [1470/2000] TrainLoss = 0.4276 , Actual loss on HF:0.2293\n",
      "Epoch = [1480/2000] TrainLoss = 0.4266 , Actual loss on HF:0.2301\n",
      "Epoch = [1490/2000] TrainLoss = 0.4289 , Actual loss on HF:0.2311\n",
      "Epoch = [1500/2000] TrainLoss = 0.4299 , Actual loss on HF:0.2373\n",
      "Epoch = [1510/2000] TrainLoss = 0.4328 , Actual loss on HF:0.2327\n",
      "Epoch = [1520/2000] TrainLoss = 0.4285 , Actual loss on HF:0.23\n",
      "Epoch = [1530/2000] TrainLoss = 0.4317 , Actual loss on HF:0.2275\n",
      "Epoch = [1540/2000] TrainLoss = 0.431 , Actual loss on HF:0.2253\n",
      "Epoch = [1550/2000] TrainLoss = 0.4279 , Actual loss on HF:0.2235\n",
      "Epoch = [1560/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2214\n",
      "Epoch = [1570/2000] TrainLoss = 0.4288 , Actual loss on HF:0.2139\n",
      "Epoch = [1580/2000] TrainLoss = 0.4258 , Actual loss on HF:0.2166\n",
      "Epoch = [1590/2000] TrainLoss = 0.428 , Actual loss on HF:0.2191\n",
      "Epoch = [1600/2000] TrainLoss = 0.4307 , Actual loss on HF:0.2153\n",
      "Epoch = [1610/2000] TrainLoss = 0.4271 , Actual loss on HF:0.2147\n",
      "Epoch = [1620/2000] TrainLoss = 0.429 , Actual loss on HF:0.2142\n",
      "Epoch = [1630/2000] TrainLoss = 0.4297 , Actual loss on HF:0.2182\n",
      "Epoch = [1640/2000] TrainLoss = 0.4266 , Actual loss on HF:0.218\n",
      "Epoch = [1650/2000] TrainLoss = 0.4309 , Actual loss on HF:0.215\n",
      "Epoch = [1660/2000] TrainLoss = 0.4272 , Actual loss on HF:0.2131\n",
      "Epoch = [1670/2000] TrainLoss = 0.4254 , Actual loss on HF:0.2148\n",
      "Epoch = [1680/2000] TrainLoss = 0.4288 , Actual loss on HF:0.214\n",
      "Epoch = [1690/2000] TrainLoss = 0.4287 , Actual loss on HF:0.2158\n",
      "Epoch = [1700/2000] TrainLoss = 0.4311 , Actual loss on HF:0.2138\n",
      "Epoch = [1710/2000] TrainLoss = 0.4273 , Actual loss on HF:0.2109\n",
      "Epoch = [1720/2000] TrainLoss = 0.4294 , Actual loss on HF:0.208\n",
      "Epoch = [1730/2000] TrainLoss = 0.4268 , Actual loss on HF:0.2083\n",
      "Epoch = [1740/2000] TrainLoss = 0.4299 , Actual loss on HF:0.209\n",
      "Epoch = [1750/2000] TrainLoss = 0.4253 , Actual loss on HF:0.2088\n",
      "Epoch = [1760/2000] TrainLoss = 0.4258 , Actual loss on HF:0.2145\n",
      "Epoch = [1770/2000] TrainLoss = 0.4306 , Actual loss on HF:0.215\n",
      "Epoch = [1780/2000] TrainLoss = 0.4258 , Actual loss on HF:0.2133\n",
      "Epoch = [1790/2000] TrainLoss = 0.4275 , Actual loss on HF:0.21\n",
      "Epoch = [1800/2000] TrainLoss = 0.4258 , Actual loss on HF:0.2127\n",
      "Epoch = [1810/2000] TrainLoss = 0.4302 , Actual loss on HF:0.2119\n",
      "Epoch = [1820/2000] TrainLoss = 0.4291 , Actual loss on HF:0.208\n",
      "Epoch = [1830/2000] TrainLoss = 0.4247 , Actual loss on HF:0.2107\n",
      "Epoch = [1840/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2065\n",
      "Epoch = [1850/2000] TrainLoss = 0.428 , Actual loss on HF:0.2043\n",
      "Epoch = [1860/2000] TrainLoss = 0.4282 , Actual loss on HF:0.2032\n",
      "Epoch = [1870/2000] TrainLoss = 0.4276 , Actual loss on HF:0.1983\n",
      "Epoch = [1880/2000] TrainLoss = 0.4313 , Actual loss on HF:0.195\n",
      "Epoch = [1890/2000] TrainLoss = 0.4282 , Actual loss on HF:0.1934\n",
      "Epoch = [1900/2000] TrainLoss = 0.4274 , Actual loss on HF:0.1938\n",
      "Epoch = [1910/2000] TrainLoss = 0.4282 , Actual loss on HF:0.1914\n",
      "Epoch = [1920/2000] TrainLoss = 0.4282 , Actual loss on HF:0.1894\n",
      "Epoch = [1930/2000] TrainLoss = 0.427 , Actual loss on HF:0.1886\n",
      "Epoch = [1940/2000] TrainLoss = 0.431 , Actual loss on HF:0.1886\n",
      "Epoch = [1950/2000] TrainLoss = 0.4284 , Actual loss on HF:0.1879\n",
      "Epoch = [1960/2000] TrainLoss = 0.4282 , Actual loss on HF:0.1885\n",
      "Epoch = [1970/2000] TrainLoss = 0.4286 , Actual loss on HF:0.1877\n",
      "Epoch = [1980/2000] TrainLoss = 0.4308 , Actual loss on HF:0.1905\n",
      "Epoch = [1990/2000] TrainLoss = 0.4291 , Actual loss on HF:0.1891\n"
     ]
    }
   ],
   "source": [
    "%run Unet_MRI_7T3.py --num-chans 8 --batch-size 1 --checkpoint checkpoint/best_model.pt  --challenge multicoil --data-path \\ --num_coil 8 --device cpu --lr 0.001 --num-epochs 2000 --report-interval 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "epoch_5000 = torch.load('test.pt')\n",
    "print(epoch_5000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 128])\n",
      "torch.Size([128, 128, 8])\n"
     ]
    }
   ],
   "source": [
    "epoch_5000 = epoch_5000.squeeze(0)\n",
    "print(epoch_5000.shape)\n",
    "epoch_5000 = epoch_5000.permute(1,2,0)\n",
    "print(epoch_5000.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accquired @ 3T')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_5000 = epoch_5000.detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Accquired\n",
    "plt.subplot(121),\n",
    "plt.imshow(np.sqrt(np.sum(abs(epoch_5000),2)), cmap='gray')\n",
    "plt.title('Accquired @ 3T')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
